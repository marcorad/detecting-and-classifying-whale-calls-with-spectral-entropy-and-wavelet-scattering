# General Reponse and Notes for Reviewers

- The original purpose of this paper is to show how WS can be used as a convenient TF decomposition to perform detection and classification simultaneously, thereby combining the methods of two usually separate systems. We have revised some parts that makes this goal absolutely clear. 
- Our original codebase is in MATLAB, with some inefficient implementations. THe organisation of the codebase will also be difficult to follow for readers. As such, we have opted to redo our entire codebase (originally in MATLAB) in python for public availability. In the new codebase, we follow the scattering computations optimally similar to Kymatio implementations, which is reflected in the paper.
- Since we have switched our implementation language, note that the figures will have different style than in the first version provided.
- Our detection method of utilising GMMs to fit noise and signal levels in the entropy has been reinvistigated. There is a massive limitation of this technique: if there are no significant signals present, this technique will produce gibberish output, as the GMM fit will then attempt to fit 2 Gaussians to the distribution of the noise entropy level only. We have taken some ideas for the suggested paper by reviewer 2, Helble et. al. (2012), to perform a robust distribution estimate of the noise entropy, and then provide detector output as an hypothesis test: "how extreme is the observed entropy level compared to the noise entropy?", thereby achieving the same result with single PDF instead of 2 Gaussians as is the case by the GMM fit. The proposed method therefore remains very similar to what the GMM tries to achieve.
- Regarding the state of the dataset, we cannot justify repairing 187 hours of audio annotations, as it is not within the intended scope of this paper. Furthermore, the SNR of many calls can be very low, so even experienced analysts may have trouble with positive identification. Our initial intension was to evaluate the open-source dataset as-is, thereby highlighting the difficulty of bio-acoustic real-world datasets, without biasing our methods to data pre-selection. However, we understand that it is very difficult to substantiate our methods without a reliable dataset. As such, we have opted limit the dataset to a subset of 19 hours of audio in which we repaired the annotations. We now evaluate only (`Bm-Ant-A/B/Z` and `Bm-D` classes), as the Fin whale (`Bp`) annotations are too rare. 
- We provide our repaired dataset subset as supplementary materials for this paper.
- We have changed the way we evaluate our classification performance to be more realistic to real-world training sets. We now opt to measure how much a classification system can improve detections from the proposed detector, by again evaluating recall and false positives per hour (linearly related to precision).
- We have reworked our figures, including removing figures we deem unnecessary, which now has a different style due to the Python implementation.

# Reviewer 1
| Request (Paraphrased) | Response |
| ------- | -------- |
| No source code for WS implementation provided. | We have provided our re-written source code in the form of a public GitHub repository. 
| Critical downsampling ambiguity: original implementations are path dependent, whereas the custom implementation is not (ambiguous). | Our original implementation only critically downsamples the largest $\lambda$ optimally, and does not perform optimal computations. See the general response notes for the new implementation and codebase, which very closely follows Kymatio. |
| Incorrect description of admissibility criterion. | This definition is not necessary for understanding the paper, so we have removed it. |
| $\psi$ is used for level 1 and 2 WS, must be clarified. | We changed the notation for clarity and more explicitly defined the symbols, noting any abuse of notation. |
| Eqn. (10) unused in the publication. | We have removed this equation. |
| Provide the unit of the invariance scale $T$. | We have opted to more closely follow the definition of invariance scale with reference to Kymatio, although we generalise it to a factor $d$ (in samples), instead of $2^J$. |
| "Information leakage" is an imprecise description of time-support exceeding $T$. | We have switched to the linearly spaced filters instead, as it is now required for the improved classification section. We describe linearly spaced filters and their bandwidth in detail to reduce confusion. |
| Spectral entropy with WS is interesting, highlight this section. | We have reworked the paper in a way that highlights SE much more - nearly half of the paper now focuses on SE and its improvements/stastistical discussions. |
| Siddiqui (1962), "Some problems connected with Rayleigh distributions": discuss statistical implications of amplitude spectra in whitening, with Liutkus and Badeau (2015), "Generalized Wiener filtering with fractional power spectrograms", as a possible favourable argument for our use case. | We have included the requested theory, and provided discussions on how this links to our whitening procedures. For simplicity, we neglect the fractional power spectrogram and instead whiten via the power spectrogram, otherwise we introduce a the fractional power exponent hyperparameter (as in Badeau, 2015) which is not necessary for for this paper to illustrate the methods. |
| Eqn. (19) should link with a discussion of PCEN. | We have provided a discussion of PCEN, with Lostanlen et. al. (2019), "Per-Channel Energy Normalization: Why and How" as reference in our whitening section. |
| Remove dogmatic bias against neural networks. | We have instead opted to provide a more holistic discussion of the current state of the art of NNs, along with their techniques and features, and how it can still be limiting in the world of bioacoustics, depending on the use-case. The focus of the paper now is not to compete with NNs, but instead evaluate WS in terms of the common PAM practices of signal detection and call classification. |
| Describe the features used as input by NNs, which is not just "mostly MFCCs", as this seems biased against NNs. | We have removed this claim, see above. | 
| Fig. 6 should expand the acronyms in the caption. | We have expanded the acronyms in all our figures. |

# Reviewer 2
| Request (Paraphrased) | Response |
| ------- | -------- |
| Detector algorithm (automatic entropy scaling with GMMs) seems overly complex. | We have reconsidered our method, and opted to simplify it by considering only the distribution of the of noise entropy level, thereby still providing probabilistic output, along with median filtering as a method to stabilise the "step responses" produced by signals. Please see the general comments section on the reconsidered change. |
| Add the performance of BLED with adaptive thresholding and whitening. | The Nuttall energy detector replaced "BLED" (since it is a generalised definition of BLED), which is measured with AW included. Scattering coefficients and STFT are now compared for all evaluated detectors, as we feel it is a pertinent question the paper should address. |
| Describe the gains obtained by WS instead of the standard FFT/STFT. | We have provided a more in-depth discussion of the gains obtained from WS versus the STFT for entropy/energy calculation. However, it is likely that a post-processed STFT can obtain similar results. The main benefits are the way the filters are placed, and the low-pass filtering which can stabilise power fluctuations - we now mention this in the paper. |
| Computational complexity of WS versus STFT | We have included the computational complexity metrics. WS is undoubtedly slower than the STFT (not by too much), which we discuss in detail in terms of time complexity of the FFTs required for convolution. |
| Benchmark the detectors against Nuttall (1994), "Detection performance of power-law processors for random signals of unknown location, structure, extent, and strength", Nuttall (1996), "Near-optimum detection performance of power-law processors for random signals of unknown locations, structure, extent, and arbitrary strengths" and Helble et. al. (2012), "A generalized power-law detection lgorithm for humpback whale vocalizations" | We have included these detectors in our comparisons, and used the Nuttall detector as a replacement of BLED, as the Nuttall detector is a generalisation of BLED. We have also done away with evaluating our previous method (Rademan et. al., 2023), as it adds no value to the paper due its lack of noise-adaptivity and failure when no calls are present in a file. Additionally, it clutters the graph of our new results, and we feel that the detectors we now evaluate provide better insight to the effect of using S1 coefficients as input to detectors. |
| Precision/recall along with TPR/FPR, following Hildebrand et. al. (2022), "Performance metrics for marine mammal signal detection and classification". | We have switched our evaluation to Precision/Recall and False Positives per Hour (linearly related to Precision) + Recall. | 
| Reconsider the GMM thresholding technique, it seems to require hyper-parameter tuning and the "fudging" of distributions. Perhaps use target SNR for adaptive threshold? | We have remained in the probabilistic spirit of this paper by deriving an approximate noise SE distribution, and treating SE as a test statistic. This type of test is much simpler than the GMM, and does not fail when only noise is present (GMM fitting will fail if no signals are in the audio). |
| The classification section description is lacking. LDA is vague, with chi-square feature selection requiring clarification. | Feature selection has been dropped as we did not deem it necessary - it obfuscates the main points of the paper. We have expanded on how we prepare features for LDA and how an LDA classifier works. |
| Take the time to repair repair the dataset, as it does not appear that it would take terrible long, so as to strengthen the conclusions of the classification section. | See the general comments section. |
| The hyper-parameters $\alpha, \gamma$ does not appear stable as a function of the training size. It does not seem to bode well for robustness. How important is the value of the parameter $\gamma$? | We have reconsidered our method, and instead choose $\gamma$ via the Ledoit-Wolf estimator (included in Scikit-learn), and completely removed the signal/noise priors by fixing them both 0.5 for simplicity. Although the priors can be tuned for a certain amount of noise rejection, it is simpler to fix them in this paper, since the goal is to demonstrate improved Precision (reduced false positives per hour) of the detectors. We now deem it unnecessary to attempt to optimise these parameters for us to illustrate the main points of the paper. |
| Peer reviewed reference required for Anne and Mallat (2013). | We updated this reference. We assume you meant "Anden and Mallat" - we cited the 2013 preprint, but changed it to the peer-reviewed version published in 2014. |
| Lines 417-418 are incomprehensible. | We have removed the feature selection, as it is no longer necessary for illustrating the point we want to make with adding a classifier after detection.
| Mathematical notation for WS is difficult to follow. For example, define $*$ as the convolution operator. | We have changed notation to provide more clarity, in line with reviewer 1's comments. |
| Replace figure 3 with S1 and S2 scattering amplitudes for one or two calls to be more instructive. | In our new figures, we have included S1 amplitudes for a illustrative `Bm-D` and `Bm-Ant` calls. S2 scattering amplitudes do not visualise very well (see Anden and Mallat, 2014) unless a very specific audio example is used with oversampling S2, and will not provide any additional clarity in this paper. |
| The GMM section is incremental to a publication of the same authors, so keep the details at a minimum. | We have completely done away with the GMM section, as we arrived at a much simpler method. We therefore have reduced the dependance on our previous paper, which does not work well without noise adaptivity, and fails completely if no signals are present in an audio file. As such, we have decided to not evaluate our previous method for comparison, as it clutters the graphs and adds no value to the points made in this paper. |
| The paper is long and can lose focus at times. | We have condensed as much material as possible in favour of a shorter paper. Nearly the entire paper has been reworked to accommodate this request. | 